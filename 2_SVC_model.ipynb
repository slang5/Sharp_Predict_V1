{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5cf57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data features\n",
    "data_features = pd.read_csv('processed_data/data_features.csv', header=[0,1], index_col=0, parse_dates=True)\n",
    "# Forward fill missing values\n",
    "data_features = data_features.ffill()\n",
    "\n",
    "# Quick look at the data\n",
    "print('features :' + str(data_features.keys().get_level_values(1).unique()))\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data_features to include only rows after the date N due to feature availability\n",
    "N = 151\n",
    "filtered_data = data_features[data_features.index > data_features.index[N]]\n",
    "first_date = filtered_data.index.min()\n",
    "last_date = filtered_data.index.max()\n",
    "print(f'Data filtered to include only rows after {first_date}')\n",
    "print(f\"Data filtered to include only rows before {last_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890709bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model and parameters for each period and ticker\n",
    "\n",
    "duration_period = 0.5 # % year\n",
    "window_size = int(252 * duration_period)\n",
    "\n",
    "trigger_up_grid = np.linspace(0, 5, 10)\n",
    "trigger_down_grid = np.linspace(0, -5, 10)\n",
    "C_grid = np.linspace(0.00, 0.3, 5)\n",
    "max_iter_value = 10_000\n",
    "\n",
    "filtered_data = filtered_data.ffill()\n",
    "Tickers = filtered_data.columns.get_level_values(0).unique()\n",
    "tscv_nSplit = len(filtered_data) // window_size - 1\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=tscv_nSplit, max_train_size=window_size)\n",
    "\n",
    "metrics_perf = []\n",
    "current_step = 0\n",
    "total_steps = tscv.get_n_splits(filtered_data)\n",
    "\n",
    "for train_index, test_index in tscv.split(filtered_data):\n",
    "    print(f'Processing fold {current_step + 1} of {total_steps}', end=' | ')\n",
    "    print(f'Start Train: {filtered_data.index[train_index].min()} | End Train: {filtered_data.index[train_index].max()} | Start Test: {filtered_data.index[test_index].min()} | End Test: {filtered_data.index[test_index].max()}')\n",
    "    current_step += 1\n",
    "\n",
    "    train_data, test_data = filtered_data.iloc[train_index], filtered_data.iloc[test_index]\n",
    "\n",
    "    for ticker in Tickers:\n",
    "        X_train, Y_train = train_data[ticker].drop(columns=['Signal']), train_data[ticker]['Signal']\n",
    "        X_test, Y_test = test_data[ticker].drop(columns=['Signal']), test_data[ticker]['Signal']\n",
    "\n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            SVC(max_iter=max_iter_value),\n",
    "            param_grid={'C': C_grid},\n",
    "            scoring='neg_mean_squared_error',\n",
    "            cv=TimeSeriesSplit(n_splits=2, max_train_size=window_size),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train_scaled, Y_train)\n",
    "\n",
    "        best_C = grid_search.best_params_['C']\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        Y_train_pred_src = best_model.predict(X_train_scaled)\n",
    "        Y_test_pred_src = best_model.predict(X_test_scaled)\n",
    "\n",
    "        # Find optimal triggers based on performance metrics\n",
    "        best_trigger_up = None\n",
    "        best_trigger_down = None\n",
    "        best_return_train = -np.inf\n",
    "        best_return_test = -np.inf\n",
    "\n",
    "        Return_test = np.array(X_test.DD_Return.shift(-1).fillna(0))\n",
    "        Return_train = np.array(X_train.DD_Return.shift(-1).fillna(0))\n",
    "\n",
    "        for trigger_up in trigger_up_grid:\n",
    "            for trigger_down in trigger_down_grid:\n",
    "                Y_train_pred = np.where(Y_train_pred_src > trigger_up, 1, \n",
    "                                       np.where(Y_train_pred_src < trigger_down, -1, 0))\n",
    "                Y_test_pred = np.where(Y_test_pred_src > trigger_up, 1, \n",
    "                                      np.where(Y_test_pred_src < trigger_down, -1, 0))\n",
    "\n",
    "                # Evaluate performance\n",
    "                return_predicted_train = float(np.sum(Y_train_pred * Return_train))\n",
    "                return_predicted_test = float(np.sum(Y_test_pred * Return_test))\n",
    "\n",
    "                if return_predicted_train > best_return_train:\n",
    "                    best_return_train = return_predicted_train\n",
    "                    best_return_test = return_predicted_test\n",
    "                    best_trigger_up = trigger_up\n",
    "                    best_trigger_down = trigger_down\n",
    "\n",
    "        best_market_return_test = float(np.sum(Return_test))\n",
    "        best_market_return_train = float(np.sum(Return_train))\n",
    "\n",
    "        metrics_perf.append({\n",
    "            'Ticker': ticker,\n",
    "            'Train Start': train_data.index.min(),\n",
    "            'Train End': train_data.index.max(),\n",
    "            'Test Start': test_data.index.min(),\n",
    "            'Test End': test_data.index.max(),\n",
    "            'Return_Predicted_Train': best_return_train,\n",
    "            'Return_Predicted_Test': best_return_test,\n",
    "            'Market_Return_Train': best_market_return_train,\n",
    "            'Market_Return_Test': best_market_return_test,\n",
    "            'Ratio_Train': best_return_train / best_market_return_train if best_market_return_train != 0 else 0,\n",
    "            'Model_train_>_Market_train': 1 if best_return_train > best_market_return_train else 0,\n",
    "            'Model_test_>_Market_test': 1 if best_return_test > best_market_return_test else 0,\n",
    "            'Trigger_Up': best_trigger_up,\n",
    "            'Trigger_Down': best_trigger_down,\n",
    "            'C': best_C,\n",
    "        })\n",
    "\n",
    "metrics_perf_df = pd.DataFrame(metrics_perf)\n",
    "metrics_perf_df.to_csv('model/svc/metrics_raw_data.csv', index=False)\n",
    "metrics_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2732c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compute the average Return_Predicted_Train and Return_Predicted_Test for Train Start dates batch\n",
    "summary_graph_raw = metrics_perf_df.groupby(['Train Start', 'Train End', 'Test Start', 'Test End']).agg({\n",
    "    'Return_Predicted_Train': 'mean',\n",
    "    'Market_Return_Train': 'mean',\n",
    "    'Return_Predicted_Test': 'mean',\n",
    "    'Market_Return_Test': 'mean',\n",
    "})\n",
    "summary_graph_raw.to_csv('model/svc/metrics_raw_summary.csv', index=True)\n",
    "summary_graph_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth_market = 4\n",
    "linewidth_model = 2\n",
    "plt.figure(figsize=(20, 13))\n",
    "plt.plot(summary_graph_raw.index.get_level_values('Train Start'), summary_graph_raw['Return_Predicted_Train'], label='Return_Predicted_Train', marker='o', linewidth=linewidth_model, color='cyan')\n",
    "plt.plot(summary_graph_raw.index.get_level_values('Train Start'), summary_graph_raw['Market_Return_Train'], label='Market_Return_Train', marker='x', linewidth=linewidth_market, color='darkblue')\n",
    "plt.plot(summary_graph_raw.index.get_level_values('Test Start'), summary_graph_raw['Return_Predicted_Test'], label='Return_Predicted_Test', marker='o', linewidth=linewidth_model, color='coral')\n",
    "plt.plot(summary_graph_raw.index.get_level_values('Test Start'), summary_graph_raw['Market_Return_Test'], label='Market_Return_Test', marker='x', linewidth=linewidth_market, color='darkred')\n",
    "plt.xlabel('Train Start Date')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('Average Returns over Training Periods')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f868e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute yield and std for each series from summary_graph\n",
    "\n",
    "for serie in ['Return_Predicted_Train', 'Market_Return_Train', 'Return_Predicted_Test', 'Market_Return_Test']:\n",
    "    yields_raw = summary_graph_raw[serie].values\n",
    "    mean_yield_raw = np.mean(yields_raw)\n",
    "    std_yield_raw = np.std(yields_raw)\n",
    "    sharpe_ratio_raw = mean_yield_raw / std_yield_raw if std_yield_raw != 0 else 0\n",
    "    print(f\"{serie} - Mean Yield: {mean_yield_raw:.4f}, Std Dev: {std_yield_raw:.4f}, Sharpe Ratio: {sharpe_ratio_raw:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ab9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute P&L evolution over time for each series\n",
    "Start_dates = summary_graph_raw.index.get_level_values('Test Start')\n",
    "End_dates = summary_graph_raw.index.get_level_values('Test End')\n",
    "\n",
    "Start_End_dates = zip(Start_dates, End_dates)\n",
    "# Compute P&L evolution over time for each series\n",
    "PNL_data_raw = summary_graph_raw.reset_index()[['Test Start', 'Test End', 'Return_Predicted_Train', 'Market_Return_Train', 'Return_Predicted_Test', 'Market_Return_Test']].rename(columns={'Test Start': 'Start', 'Test End': 'End'})\n",
    "for start, end in Start_End_dates:\n",
    "    for serie in ['Return_Predicted_Train', 'Market_Return_Train', 'Return_Predicted_Test', 'Market_Return_Test']:\n",
    "        PNL_data_raw.loc[(PNL_data_raw['Start'] == start) & (PNL_data_raw['End'] == end), serie] = summary_graph_raw.loc[(summary_graph_raw.index.get_level_values('Test Start') == start) & (summary_graph_raw.index.get_level_values('Test End') == end), serie].values[0]\n",
    "\n",
    "for serie in ['Return_Predicted_Train', 'Market_Return_Train', 'Return_Predicted_Test', 'Market_Return_Test']:\n",
    "    PNL_data_raw[serie] = np.exp(PNL_data_raw[serie])\n",
    "    PNL_data_raw[serie] = PNL_data_raw[serie].cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ccb755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PNL_data.set_index('Start', inplace=True)\n",
    "linewidth_market = 4\n",
    "linewidth_model = 2\n",
    "plt.figure(figsize=(20, 13))\n",
    "plt.plot(PNL_data_raw.index, PNL_data_raw['Return_Predicted_Train'], label='Return_Predicted_Train', linewidth=linewidth_model, color='cyan')\n",
    "plt.plot(PNL_data_raw.index, PNL_data_raw['Market_Return_Train'], label='Market_Return_Train', linewidth=linewidth_market, color='darkblue')\n",
    "plt.plot(PNL_data_raw.index, PNL_data_raw['Return_Predicted_Test'], label='Return_Predicted_Test', linewidth=linewidth_model, color='coral')\n",
    "plt.plot(PNL_data_raw.index, PNL_data_raw['Market_Return_Test'], label='Market_Return_Test', linewidth=linewidth_market, color='darkred')\n",
    "plt.xlabel('Start Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.title('Cumulative P&L Evolution over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "PNL_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_start_list = metrics_perf_df['Train Start'].unique().tolist()\n",
    "Ticker_per_Period = {}\n",
    "\n",
    "quantile_above = 0.75\n",
    "for train_start in Train_start_list:\n",
    "    quantile_n = metrics_perf_df[metrics_perf_df['Train Start'] == train_start].Ratio_Train.quantile(quantile_above)\n",
    "    selected_tickers = metrics_perf_df[(metrics_perf_df['Train Start'] == train_start) &\n",
    "                                       (metrics_perf_df['Ratio_Train'] >= quantile_n)]['Ticker'].tolist()\n",
    "    Ticker_per_Period[train_start] = selected_tickers\n",
    "\n",
    "print(\"Selected Tickers per Training Period:\")\n",
    "for period, tickers in Ticker_per_Period.items():\n",
    "    print(f\"{period}: {tickers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tscv_selected = TimeSeriesSplit(n_splits=tscv_nSplit, max_train_size=window_size)\n",
    "\n",
    "metrics_perf_selected = []\n",
    "current_step_selected = 0\n",
    "total_steps_selected = tscv_selected.get_n_splits(filtered_data)\n",
    "\n",
    "for train_index, test_index in tscv_selected.split(filtered_data):\n",
    "    print(f'Processing fold {current_step_selected + 1} of {total_steps_selected}')\n",
    "    current_step_selected += 1\n",
    "\n",
    "    train_data, test_data = filtered_data.iloc[train_index], filtered_data.iloc[test_index]\n",
    "    tickers_in_period = Ticker_per_Period.get(train_data.index.min(), [])\n",
    "\n",
    "    for ticker in tickers_in_period:\n",
    "        X_train, Y_train = train_data[ticker].drop(columns=['Signal']), train_data[ticker]['Signal']\n",
    "        X_test, Y_test = test_data[ticker].drop(columns=['Signal']), test_data[ticker]['Signal']\n",
    "\n",
    "        # Standardize features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Fit linear regression model\n",
    "        model = SVC(C=metrics_perf_df[(metrics_perf_df['Ticker'] == ticker) & (metrics_perf_df['Train Start'] == train_data.index.min())]['C'].values[0], max_iter=max_iter_value)\n",
    "        model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        Y_train_pred_src = model.predict(X_train_scaled)\n",
    "        Y_test_pred_src = model.predict(X_test_scaled)\n",
    "\n",
    "        # Use optimal triggers based on previous model performance\n",
    "        best_trigger_up = metrics_perf_df[(metrics_perf_df['Ticker'] == ticker) &\n",
    "                                          (metrics_perf_df['Train Start'] == train_data.index.min())]['Trigger_Up'].values[0]\n",
    "        best_trigger_down = metrics_perf_df[(metrics_perf_df['Ticker'] == ticker) &\n",
    "                                            (metrics_perf_df['Train Start'] == train_data.index.min())]['Trigger_Down'].values[0]\n",
    "\n",
    "    \n",
    "        # Define performance metrics (model returns based on triggers)\n",
    "        Y_train_pred = np.where(Y_train_pred_src > best_trigger_up, 1, np.where(Y_train_pred_src < best_trigger_down, -1, 0))\n",
    "        Y_test_pred = np.where(Y_test_pred_src > best_trigger_up, 1, np.where(Y_test_pred_src < best_trigger_down, -1, 0))\n",
    "        #Y_train_pred = np.where(Y_train_pred_src > best_trigger_up, -1, np.where(Y_train_pred_src < best_trigger_down, 1, 0))\n",
    "        #Y_test_pred = np.where(Y_test_pred_src > best_trigger_up, -1, np.where(Y_test_pred_src < best_trigger_down, 1, 0))\n",
    "        \n",
    "        # Evaluate performance\n",
    "        Return = np.array(X_test.DD_Return.shift(-1).fillna(0))\n",
    "\n",
    "        return_predicted_train = float(np.sum(Y_train_pred * X_train.DD_Return.shift(-1).fillna(0)))\n",
    "        return_predicted_test = float(np.sum(Y_test_pred * Return))\n",
    "\n",
    "        market_return_train = float(np.sum(X_train.DD_Return.shift(-1).fillna(0)))\n",
    "        market_return_test = float(np.sum(Return))\n",
    "\n",
    "        ratio_train = return_predicted_train / market_return_train if market_return_train != 0 else 0\n",
    "        ratio_test = return_predicted_test / market_return_test if market_return_test != 0 else 0    \n",
    "              \n",
    "        metrics_perf_selected.append({\n",
    "            'Ticker': ticker,\n",
    "            'Train Start': train_data.index.min(),\n",
    "            'Train End': train_data.index.max(),\n",
    "            'Test Start': test_data.index.min(),\n",
    "            'Test End': test_data.index.max(),\n",
    "            'Return_Predicted_Train': return_predicted_train,\n",
    "            'Return_Predicted_Test': return_predicted_test,\n",
    "            'Market_Return_Train': market_return_train,\n",
    "            'Market_Return_Test': market_return_test,\n",
    "            'Ratio_Train': ratio_train,\n",
    "            'Ratio_Test': ratio_test,\n",
    "            'Model_train_>_Market_train': 1 if return_predicted_train > market_return_train else 0,\n",
    "            'Model_test_>_Market_test': 1 if return_predicted_test > market_return_test else 0,\n",
    "            'Trigger_Up': best_trigger_up,\n",
    "            'Trigger_Down': best_trigger_down,\n",
    "            'C': model.C,\n",
    "        })\n",
    "\n",
    "metrics_perf_selected_df = pd.DataFrame(metrics_perf_selected)\n",
    "metrics_perf_selected_df.to_csv('model/svc/metrics_selected_data.csv', index=False)\n",
    "metrics_perf_selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets compute the average Return_Predicted_Train and Return_Predicted_Test for Train Start dates batch\n",
    "summary_graph_selected = metrics_perf_selected_df.groupby(['Train Start', 'Train End', 'Test Start', 'Test End']).agg({\n",
    "    'Return_Predicted_Train': 'mean',\n",
    "    'Market_Return_Train': 'mean',\n",
    "    'Return_Predicted_Test': 'mean',\n",
    "    'Market_Return_Test': 'mean',\n",
    "})\n",
    "summary_graph_selected.to_csv('model/svc/metrics_selected_summary.csv', index=True)\n",
    "summary_graph_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth_market = 4\n",
    "linewidth_model = 2\n",
    "plt.figure(figsize=(20, 13))\n",
    "plt.plot(summary_graph_selected.index.get_level_values('Train Start'), summary_graph_selected['Return_Predicted_Train'], label='Return_Predicted_Train', marker='o', linewidth=linewidth_model, color='cyan')\n",
    "plt.plot(summary_graph_selected.index.get_level_values('Train Start'), summary_graph_selected['Market_Return_Train'], label='Market_Return_Train', marker='x', linewidth=linewidth_market, color='darkblue')\n",
    "plt.plot(summary_graph_selected.index.get_level_values('Test Start'), summary_graph_selected['Return_Predicted_Test'], label='Return_Predicted_Test', marker='o', linewidth=linewidth_model, color='coral')\n",
    "plt.plot(summary_graph_selected.index.get_level_values('Test Start'), summary_graph_selected['Market_Return_Test'], label='Market_Return_Test', marker='x', linewidth=linewidth_market, color='darkred')\n",
    "plt.xlabel('Train Start Date')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('Average Returns over Training Periods')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca5de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute yield and std for each series from summary_graph\n",
    "\n",
    "for serie in ['Return_Predicted_Train', 'Market_Return_Train', 'Return_Predicted_Test', 'Market_Return_Test']:\n",
    "    yields = summary_graph_selected[serie].values\n",
    "    mean_yield = np.mean(yields)\n",
    "    std_yield = np.std(yields)\n",
    "    sharpe_ratio = mean_yield / std_yield if std_yield != 0 else 0\n",
    "    print(f\"{serie} - Mean Yield: {mean_yield:.4f}, Std Dev: {std_yield:.4f}, Sharpe Ratio: {sharpe_ratio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9586493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute P&L evolution over time for each series\n",
    "Start_dates = summary_graph_selected.index.get_level_values('Test Start')\n",
    "End_dates = summary_graph_selected.index.get_level_values('Test End')\n",
    "\n",
    "Start_End_dates = zip(Start_dates, End_dates)\n",
    "# Compute P&L evolution over time for each series\n",
    "PNL_data = summary_graph_selected.reset_index()[['Test Start', 'Test End', 'Return_Predicted_Train', 'Market_Return_Train', 'Return_Predicted_Test', 'Market_Return_Test']].rename(columns={'Test Start': 'Start', 'Test End': 'End'})\n",
    "for start, end in Start_End_dates:\n",
    "    for serie in ['Return_Predicted_Train', 'Market_Return_Train', 'Return_Predicted_Test', 'Market_Return_Test']:\n",
    "        PNL_data.loc[(PNL_data['Start'] == start) & (PNL_data['End'] == end), serie] = summary_graph_selected.loc[(summary_graph_selected.index.get_level_values('Test Start') == start) & (summary_graph_selected.index.get_level_values('Test End') == end), serie].values[0]\n",
    "\n",
    "for serie in ['Return_Predicted_Train', 'Market_Return_Train', 'Return_Predicted_Test', 'Market_Return_Test']:\n",
    "    PNL_data[serie] = np.exp(PNL_data[serie])\n",
    "    PNL_data[serie] = PNL_data[serie].cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea04406",
   "metadata": {},
   "outputs": [],
   "source": [
    "linewidth_market = 4\n",
    "linewidth_model = 2\n",
    "plt.figure(figsize=(20, 13))\n",
    "plt.plot(PNL_data.index, PNL_data['Return_Predicted_Train'], label='Return_Predicted_Train', linewidth=linewidth_model, color='cyan')\n",
    "plt.plot(PNL_data.index, PNL_data['Market_Return_Train'], label='Market_Return_Train', linewidth=linewidth_market, color='darkblue')\n",
    "plt.plot(PNL_data.index, PNL_data['Return_Predicted_Test'], label='Return_Predicted_Test', linewidth=linewidth_model, color='coral')\n",
    "plt.plot(PNL_data.index, PNL_data['Market_Return_Test'], label='Market_Return_Test', linewidth=linewidth_market, color='darkred')\n",
    "plt.xlabel('Start Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.title('Cumulative P&L Evolution over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "PNL_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare PNL data between raw and selected tickers\n",
    "\n",
    "plt.figure(figsize=(20, 13))\n",
    "\n",
    "plt.plot(PNL_data.index, PNL_data['Return_Predicted_Test'], label='Selected Tickers - Model performance', linewidth=linewidth_model, color='coral')\n",
    "plt.plot(PNL_data.index, PNL_data['Market_Return_Test'], label='Selected Tickers - Market performance', linewidth=linewidth_market, color='darkred')\n",
    "\n",
    "plt.plot(PNL_data_raw.index, PNL_data_raw['Return_Predicted_Test'], label='Raw Tickers - Model performance', linewidth=linewidth_model, color='cyan')\n",
    "plt.plot(PNL_data_raw.index, PNL_data_raw['Market_Return_Test'], label='Raw Tickers - Market performance', linewidth=linewidth_market, color='darkblue')\n",
    "\n",
    "plt.xlabel('Start Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.title('Cumulative P&L Evolution over Time')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
